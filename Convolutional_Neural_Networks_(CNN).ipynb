{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYysdyb-CaWM"
      },
      "source": [
        "# Image Classification with Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import the packages if not installed (Optional if the Colab throws error while importing packages)\n",
        "# !pip install -q tensorflow\n",
        "# !pip install -q tqdm"
      ],
      "metadata": {
        "id": "yzhfLprb4kF_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0tMfX2vR0uD"
      },
      "source": [
        "## Import dependencies and packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5HDhfftMGc_i"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uusvhUp9Gg37"
      },
      "outputs": [],
      "source": [
        "# Import TensorFlow Datasets\n",
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "# Helper libraries\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXZ44qIaG0Ru"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yR0EdgrLCaWR"
      },
      "source": [
        "## Import the Fashion MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLdCchMdCaWQ"
      },
      "source": [
        "Using Fashion MNIST dataset, which contains 70,000 grayscale images in 10 categories. The images show individual articles of clothing at low resolution (28 $\\times$ 28 pixels), as seen here:\n",
        "\n",
        "<table>\n",
        "  <tr><td>\n",
        "    <img src=\"https://tensorflow.org/images/fashion-mnist-sprite.png\"\n",
        "         alt=\"Fashion MNIST sprite\" width=\"600\">\n",
        "  </td></tr>\n",
        "  \n",
        "</table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Added a split to the training dataset, reserving 10% for use during validation**\n",
        "\n",
        "* The model is trained using `train_dataset`.\n",
        "* The model validates as it is being trained using the `validation_dataset`\n",
        "* The model is tested against `test_dataset`."
      ],
      "metadata": {
        "id": "Z8Nnzg88Dgbk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MqDQO0KCaWS"
      },
      "outputs": [],
      "source": [
        "dataset, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True, split=['train[:90%]','train[90%:]', 'test'])\n",
        "train_dataset, validation_dataset, test_dataset = dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9FDsUlxCaWW"
      },
      "source": [
        "\n",
        "\n",
        "The images are 28 $\\times$ 28 arrays, with pixel values in the range `[0, 255]`. The *labels* are an array of integers, in the range `[0, 9]`. These correspond to the *class* of clothing the image represents:\n",
        "\n",
        "<table>\n",
        "  <tr>\n",
        "    <th>Label</th>\n",
        "    <th>Class</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>0</td>\n",
        "    <td>T-shirt/top</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td>Trouser</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>2</td>\n",
        "    <td>Pullover</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>3</td>\n",
        "    <td>Dress</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>4</td>\n",
        "    <td>Coat</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>5</td>\n",
        "    <td>Sandal</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>6</td>\n",
        "    <td>Shirt</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>7</td>\n",
        "    <td>Sneaker</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>8</td>\n",
        "    <td>Bag</td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td>9</td>\n",
        "    <td>Ankle boot</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "Each image is mapped to a single label. Since the *class names* are not included with the dataset, store them here to use later when plotting the images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IjnLH5S2CaWx"
      },
      "outputs": [],
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal',      'Shirt',   'Sneaker',  'Bag',   'Ankle boot']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brm0b_KACaWX"
      },
      "source": [
        "### Data Exploration before training\n",
        "\n",
        "This shows there are 54,000 images in the training set, 6000 images in the validation set, and 10000 images in the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MaOTZxFzi48X"
      },
      "outputs": [],
      "source": [
        "num_train_examples = len(train_dataset)\n",
        "num_validation_examples = len(validation_dataset)\n",
        "num_test_examples = len(test_dataset)\n",
        "print(\"Number of training examples: {}\".format(num_train_examples))\n",
        "print(\"Number of validation examples: {}\".format(num_validation_examples))\n",
        "print(\"Number of test examples:     {}\".format(num_test_examples))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES6uQoLKCaWr"
      },
      "source": [
        "## Data Pre-processing\n",
        "\n",
        "The value of each pixel in the image data is an integer in the range `[0,255]`. For the model to work properly, these values need to be normalized to the range `[0,1]`.\n",
        "\n",
        "The `normalize` function is used for preprocessing images and their corresponding labels, where we are using `tf.cast` which converts the pixel values of the images to tf.float32 data type (32-bit floating-point numbers). This ensures the data type is compatible with TensorFlow operations that typically work with floating-point numbers for numerical stability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAsH3Zm-76pB"
      },
      "outputs": [],
      "source": [
        "def normalize(images, labels):\n",
        "  images = tf.cast(images, tf.float32)\n",
        "  images /= 255\n",
        "  return images, labels\n",
        "\n",
        "# The map function applies the normalize function to each element in the train and test datasets\n",
        "train_dataset =  train_dataset.map(normalize)\n",
        "validation_dataset = validation_dataset.map(normalize)\n",
        "test_dataset  =  test_dataset.map(normalize)\n",
        "\n",
        "# For the first time, the data will be loaded from disk, so caching will keep them in memory, making training faster\n",
        "train_dataset =  train_dataset.cache()\n",
        "validation_dataset = validation_dataset.cache()\n",
        "test_dataset  =  test_dataset.cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIQbEiJGXM-q"
      },
      "source": [
        "### Visualizing the processed data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSzE9l7PjHx0"
      },
      "outputs": [],
      "source": [
        "# Take a single image, and remove the color dimension by reshaping\n",
        "for image, label in test_dataset.take(1):\n",
        "  break\n",
        "image = image.numpy().reshape((28,28))\n",
        "\n",
        "plt.figure()\n",
        "plt.imshow(image, cmap=plt.cm.binary)\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee638AlnCaWz"
      },
      "source": [
        "### For visualizing first 10 images from the *training set* and display the class name below each image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZTImqg_CaW1"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "i = 0\n",
        "for (image, label) in test_dataset.take(10):\n",
        "    image = image.numpy().reshape((28,28))\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(image, cmap=plt.cm.binary)\n",
        "    plt.xlabel(class_names[label])\n",
        "    i += 1\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59veuiEZCaW4"
      },
      "source": [
        "## Building the neural network requires configuring the layers of the model, then compiling the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gxg1XGm0eOBy"
      },
      "source": [
        "### Setting up the layers for network\n",
        "\n",
        "**Our network layers configuration:**\n",
        "* 2D Convolution layer - 32 filters, 3x3 kernel, ReLU activation, padding with same values\n",
        "* Max pooling layer - 2x2 kernel, 2 stride\n",
        "* 2D Convolution layer - 64 filters, 3x3 kernel, ReLU activation, padding with same values\n",
        "* Max pooling layer - 2x2 kernel, 2 stride\n",
        "* Flatten layer\n",
        "* Dense layer - 128 nodes output, ReLU activation\n",
        "* Dense layer - 10 nodes output, Softmax activation\n",
        "\n",
        "<font color='orange'><b>Stride controls how much the filter moves across the image in each step.</b></font>\n",
        "<ul>\n",
        "    <li><font color='orange'><b>Stride of 1</b>: The filter moves one pixel at a time, creating a detailed output.</font></li>\n",
        "    <li><font color='orange'><b>Stride of 2</b>: The filter skips every other pixel, making the output smaller and faster to compute.</font></li>\n",
        "</ul>\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIFXglXv_7tn"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), padding='same', activation=tf.nn.relu,\n",
        "                           input_shape=(28, 28, 1)),\n",
        "    tf.keras.layers.MaxPool2D((2, 2), strides=2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), padding='same', activation=tf.nn.relu),\n",
        "    tf.keras.layers.MaxPool2D((2, 2), strides=2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gut8A_7rCaW6"
      },
      "source": [
        "### Using `Model.compile` to compile the model\n",
        "\n",
        "**The following settings have been implemented**\n",
        "* *Loss function* â€” SparseCategoricalCrossentropy\n",
        "* *Optimizer* â€” Adam\n",
        "* *Metrics* â€” accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KvW1AzV_7tn"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKF6uW-BCaW-"
      },
      "source": [
        "## Using `Model.fit` to train the model\n",
        "\n",
        "Training is performed by calling the `model.fit` method,\n",
        "1. Feed the training data to the model using `train_dataset`.\n",
        "2. The model learns to associate images and labels.\n",
        "3. The `epochs=10` parameter limits training to 10 full iterations of the training dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_Dp8971McQ1"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.cache().shuffle(num_train_examples).batch(BATCH_SIZE)\n",
        "validation_dataset = validation_dataset.cache().batch(BATCH_SIZE)\n",
        "test_dataset = test_dataset.cache().batch(BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E0eno5Ro_7to"
      },
      "outputs": [],
      "source": [
        "model.fit(train_dataset, epochs=10, validation_data=validation_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEw4bZgGCaXB"
      },
      "source": [
        "## Evaluate accuracy with `Model.evaluate`\n",
        "\n",
        "Comparing how the model performs on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_dataset, steps=math.ceil(num_test_examples/32))\n",
        "print('Accuracy on test dataset:', test_accuracy)"
      ],
      "metadata": {
        "id": "_8R5xX5HGTur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsoS7CPDCaXH"
      },
      "source": [
        "## The model has been trained, now, to make predictions about some images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ccoz4conNCpl"
      },
      "outputs": [],
      "source": [
        "for test_images, test_labels in test_dataset.take(1):\n",
        "  test_images = test_images.numpy()\n",
        "  test_labels = test_labels.numpy()\n",
        "  predictions = model.predict(test_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gl91RPhdCaXI"
      },
      "outputs": [],
      "source": [
        "predictions.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9Kk1voUCaXJ"
      },
      "source": [
        "The model has predicted the label for each image in the testing set, showing for the first prediction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DmJEUinCaXK"
      },
      "outputs": [],
      "source": [
        "predictions[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hw1hgeSCaXN"
      },
      "source": [
        "A prediction is an array of 10 numbers, to see which label has the highest confidence value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsqenuPnCaXO"
      },
      "outputs": [],
      "source": [
        "np.argmax(predictions[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E51yS7iCCaXO"
      },
      "source": [
        "So the model is usually most confident that this image is a coat, or `class_names[4]`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sd7Pgsu6CaXP"
      },
      "outputs": [],
      "source": [
        "test_labels[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygh2yYC972ne"
      },
      "source": [
        "Visualize full set of 10 class predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvYmmrpIy6Y1"
      },
      "outputs": [],
      "source": [
        "def plot_image(i, predictions_array, true_labels, images):\n",
        "  predictions_array, true_label, img = predictions_array[i], true_labels[i], images[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img[...,0], cmap=plt.cm.binary)\n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array[i], true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4Ov9OFDMmOD"
      },
      "source": [
        "Display 0th image, predictions, and prediction array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HV5jw-5HwSmO"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions, test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ko-uzOufSCSe"
      },
      "outputs": [],
      "source": [
        "i = 12\n",
        "plt.figure(figsize=(6,3))\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions, test_labels, test_images)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions, test_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgdvGD52CaXR"
      },
      "source": [
        "## Visualize several images with their prediction\n",
        " Correct prediction labels are blue and incorrect prediction labels are red."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQlnbqaw2Qu_"
      },
      "outputs": [],
      "source": [
        "# Plot the test images, their predicted label, and the true label\n",
        "# Color correct predictions in blue, incorrect predictions in red\n",
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions, test_labels, test_images)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_value_array(i, predictions, test_labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R32zteKHCaXT"
      },
      "source": [
        "Using the trained model to make prediction for one image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRJ7JU7JCaXT"
      },
      "outputs": [],
      "source": [
        "# Grab an image from the test dataset\n",
        "img = test_images[0]\n",
        "\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lDFh5yF_CaXW"
      },
      "outputs": [],
      "source": [
        "# Add the image to a batch where it's the only member.\n",
        "img = np.array([img])\n",
        "\n",
        "print(img.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQ5wLTkcCaXY"
      },
      "source": [
        "Prediction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_rzNSdrCaXY"
      },
      "outputs": [],
      "source": [
        "predictions_single = model.predict(img)\n",
        "\n",
        "print(predictions_single)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ai-cpLjO-3A"
      },
      "outputs": [],
      "source": [
        "plot_value_array(0, predictions_single, test_labels)\n",
        "_ = plt.xticks(range(10), class_names, rotation=45)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cU1Y2OAMCaXb"
      },
      "source": [
        "`model.predict` returns a list of lists, one for each image in the batch of data, check the predictions for the single image in the batch:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tRmdq_8CaXb"
      },
      "outputs": [],
      "source": [
        "np.argmax(predictions_single[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFc2HbEVCaXd"
      },
      "source": [
        "The model predicts a label of 4 (coat)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Simple Image Classification is done âœ¨ Now, experiment by making the network complex or different data and enjoy !!ðŸ˜ŽðŸ™ƒ**"
      ],
      "metadata": {
        "id": "WO4CsGE2FMN9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ep-IlxgsFnzA"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "WO4CsGE2FMN9"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}